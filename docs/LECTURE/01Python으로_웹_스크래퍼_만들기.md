---
title: ğŸˆ Pythonìœ¼ë¡œ ì›¹ ìŠ¤í¬ë˜í¼ ë§Œë“¤ê¸° (nomad coders/ë…¸ë§ˆë“œì½”ë”)
meta:
  - name: description
    content: python nomadCoders ë…¸ë§ˆë“œì½”ë”
  - name: keywords
    content: python nomadCoders ë…¸ë§ˆë“œì½”ë”
---

# ğŸˆ Pythonìœ¼ë¡œ ì›¹ ìŠ¤í¬ë˜í¼ ë§Œë“¤ê¸° (nomad coders/ë…¸ë§ˆë“œì½”ë”)

ì‹¬ì‹¬í•´ì„œ ë“¤ì–´ë³´ëŠ” Python ê°•ì˜ .. ğŸ‘“ 
2022-04 ê°•ì˜ë¥¼ ë“¤ì—ˆì„ ë•Œ, indeed ì‚¬ì´íŠ¸ ë§ˆí¬ì—… êµ¬ì¡°ê°€ ì¢€ ë‹¬ë¼ì¡Œê³ , stackoverflow job ì‚¬ì´íŠ¸ëŠ” ì°¾ì„ ìˆ˜ ì—†ì—ˆë‹¤,,

ìš°ì„  ê°•ì˜ë¥¼ ë“£ê³ , ë°”ë€ HTMLì„ ë°°ìš´ëŒ€ë¡œ ìŠ¤í¬ë©í•‘ í•˜ì˜€ë‹¤. <u>ë”°ë¼ì„œ ê°•ì˜ì— ì‘ì„±ëœ ì½”ë“œì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ!</u>

ê°•ì˜ ì†Œì œëª© ë½‘ìœ¼ë ¤ê³  ìŠ¤í¬ë©í•‘ í™œìš©í•˜ì—¬ ì•„ë˜ì™€ ê°™ì´ ì œëª©ì„ ë½‘ì•˜ë‹¤ !

`beautiful soup` ìœ ìš©í•œ ê±° ê°™ë‹¤. ì˜ ì¨ë´ì•¼ì§€.

<h3>ğŸ”¸ py</h3>

```py
import requests
from bs4 import BeautifulSoup

result = requests.get("https://nomadcoders.co/python-for-beginners/lobby")
soup = BeautifulSoup(result.text, 'html.parser')
titles = soup.find_all("span", {"class": "px-6 py-4 whitespace-nowrap text-sm leading-5 overflow-hidden font-medium flex items-center text-gray-400"})
for title in titles:
  print(title.text)
```

<h3>ğŸ”¹ console</h3>

```html
#0.5 How to Ask for Help (02:00) 
#0.6 Code Python Online (03:08) 
#1.0 Data Types of Python (08:48) 
#1.1 Lists in Python (08:30) 
#1.2 Tuples and Dicts (06:33) 
...
ì¤‘ëµ
...
#4.6 Rendering Jobs! (12:24) 
#4.7 Export Route (08:48) 
#4.8 File Download (05:21) 
#4.9 Recap (07:28) 
#4.10 Conclusions (02:56) 
```
# âš¡ 1. THEORY

[repl.it](https://replit.com/) ì—ì„œ ê°„ë‹¨í•˜ê²Œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆë‹¤.

## 1.0 Data Types of Python

<h3>ğŸ”¸ py</h3>

```py
# python ë³€ìˆ˜ëª…ì€  snakeCaseë¡œ ì¨ì¤€ë‹¤.
a_string = 'like this'
a_number = 3
a_float = 3.12
a_boolean = False # pythonì—ì„œëŠ” ì²«ê¸€ìë¥¼ ëŒ€ë¬¸ìë¡œ ì¨ì•¼í•œë‹¤.
a_none = None # empty ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.

# ì¶œë ¥
print(type(a_number))
print(type(a_string))
print(type(a_none))
```

<h3>ğŸ”¹ console</h3>

```md
<class 'int'>
<class 'str'>
<class 'NoneType'>
```

## 1.1 Lists in Python

<h3>ğŸ”¸ py</h3>

```py
# mutable sequence (ë³€ê²½ ê°€ëŠ¥í•œ ì‹œí€€ìŠ¤)
days = ["Mon", "tue", "Wed", "Thur", "Fri"]

print("------list------")
print(days)
print("Mon" in days)
print("Man" in days)
print(days[3])
print(type(days))

print("------append------")
days.append("Sat")
print(days)

print("------reverse------")
days.reverse()
print(days)
```

<h3>ğŸ”¹ console</h3>

```md
------list------
['Mon', 'tue', 'Wed', 'Thur', 'Fri']
True
False
Thur
<class 'list'>
------append------
['Mon', 'tue', 'Wed', 'Thur', 'Fri', 'Sat']
------reverse------
['Sat', 'Fri', 'Thur', 'Wed', 'tue', 'Mon']
```

## 1.2 Tuples and Dicts

<h3>ğŸ”¸ py</h3>

```py
# immutable sequence (ë³€ê²½ ë¶ˆê°€ëŠ¥í•œ ì‹œí€€ìŠ¤)
days = ("Mon", "tue", "Wed", "Thur", "Fri")

print("------tuple------")
print(days)
print(type(days))

print("------dictionary------")
nico = {
  "name": "Nico",
  "age": 29,
  "korean": True,
  "fav_food": ["Kimchi", "Sashimi"]
}

print(type(nico))
print(nico)
nico["handsome"] = True
print(nico)
```

<h3>ğŸ”¹ console</h3>

```md
------tuple------
('Mon', 'tue', 'Wed', 'Thur', 'Fri')
<class 'tuple'>
------dictionary------
<class 'dict'>
{'name': 'Nico', 'age': 29, 'korean': True, 'fav_food': ['Kimchi', 'Sashimi']}
{'name': 'Nico', 'age': 29, 'korean': True, 'fav_food': ['Kimchi', 'Sashimi'], 'handsome': True}
```

## 1.3 Built in Functions

[ë‹¤ì–‘í•œ Functions](https://docs.python.org/3/library/functions.html)

<h3>ğŸ”¸ py</h3>

```py
print("------len------")
print(len("fjsiodjfoisjf"))

print("------type------")
age = "18"
print(type(age))
n_age = int(age)
print(type(n_age))
```

<h3>ğŸ”¹ console</h3>

```md
------len------
13
------type------
<class 'str'>
<class 'int'>
```

## 1.4 Creating a Your First Python Function

<h3>ğŸ”¸ py</h3>

```py
# ë“¤ì—¬ì“°ê¸°ë¥¼ í•´ì¤˜ì•¼ defineë¨ !
# pythonì€ {}ìœ¼ë¡œ êµ¬ë¶„í•˜ì§€ ì•ŠëŠ”ë‹¤.
def say_hello(): 
  print("hello")
  print("bye")

say_hello()
say_hello()
say_hello()
```

<h3>ğŸ”¹ console</h3>

```md
hello
bye
hello
bye
hello
bye
```

## 1.5 Function Arguments

<h3>ğŸ”¸ py</h3>

```py
def say_hello(who): 
  print("hello", who)

say_hello("Nico")
say_hello(True)
# say_hello() - error!

print("------")

def plus(a, b):
  print(a + b)
def minus(a, b = 0): # default value
  print(a - b)
  
plus(2, 5)
minus(2)
minus(2, 5)
```

<h3>ğŸ”¹ console</h3>

```md
hello Nico
hello True
------
7
2
-3
```

## 1.6 Returns

<h3>ğŸ”¸ py</h3>

```py
def p_plus(a, b):
  print(a + b)
  
def r_plus(a, b):
  return a + b
  print("test") # return ì´í›„ë¡œ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ

p_result = p_plus(2, 3)
r_result = r_plus(2, 3)

print(p_result, r_result)
```

<h3>ğŸ”¹ console</h3>

```md
5
None 5
```

## 1.7 Keyworded Arguments

<h3>ğŸ”¸ py</h3>

```py
# format
def say_hello(name, age):
  return f"Hello {name} you are {age} years old"

 # ì¸ìê°€ ë°”ë€Œì–´ë„ ê´œì°®ìŒ! ìˆœì„œê°€ ìƒê´€ì—†ë‹¤!
hello = say_hello(age = "12", name = "Nico")
print(hello)
```

<h3>ğŸ”¹ console</h3>

```md
Hello Nico you are 12 years old
```

## 1.8 Code Challenge!

7ê°œ ì—°ì‚° ê³„ì‚°ê¸° ë§Œë“¤ê¸°

<h3>ğŸ”¸ py</h3>

```py
# 7ê°œ ì—°ì‚°
def plus(a, b):
  return calc(a, b, '+')

def minus(a, b):
  return calc(a, b, '-')

def times(a, b):
  return calc(a, b, '*')

def division(a, b):
  return calc(a, b, '/')

def nega(a, b):
  return calc(a, b, 'nega')

def remain(a, b):
  return calc(a, b, '%')

def power(a, b):
  return calc(a, b, '**')
  
# validate and calcuate
def calc(a, b, func):
  try:
    a = float(a)
    b = float(b)
    try:
      if func == '+':
        return a + b
      elif func == '-':
        return a - b
      elif func == '*':
        return a * b
      elif func == '/':
        return a / b
      elif func == 'nega':
        return -a
      elif func == '**':
        return a ** b
    except:
      return 'Please check a method name.'
  except:
    return 'Please enter a number.'

print("------print(plus(3,'test'))------")
print(plus(3,'test'))
print("------print(minus(3,5))------")
print(minus(3,5))
```

<h3>ğŸ”¹ console</h3>

```md
------print(plus(3,'test'))------
Please enter a number.

------print(minus(3,5))------
-2.0
```

## 1.9 Conditionals Part One

<h3>ğŸ”¸ py</h3>

```py
def plus(a, b):
  if type(b) is int or type(b) is float:
    return a + b
  else:
    return None

print(plus(12, 1.2))
print(plus(12, "test"))
```

<h3>ğŸ”¹ console</h3>

```md
13.2
None
```

## 1.10 if else and of

<h3>ğŸ”¸ py</h3>

```py
def age_check(age):
  print(f"------you are {age}------")
  if age < 18:
    print("you cant drink")
  elif age == 18:
    print("you are new to this!")
  elif age > 20 and age < 25:
    print("you are still kind of young")
  else:
    print("enjoy your drink")
  print()

age_check(16)
age_check(18)
age_check(23)
age_check(30)
```

<h3>ğŸ”¹ console</h3>

```md
------you are 16------
you cant drink

------you are 18------
you are new to this!

------you are 23------
you are still kind of young

------you are 30------
enjoy your drink
```

## 1.11 for in

<h3>ğŸ”¸ py</h3>

```py
days = ("Mon", "Tue", "Wed", "Thur", "Fri")

for d in days:
  if d == 'Wed':
    break
  else:
    print(d)

for n in [1, 2, 3, 4, 5]:
  print(n)

for letter in "nicolas":
  print(letter)
```

<h3>ğŸ”¹ console</h3>

```md
Mon
Tue
1
2
3
4
5
n
i
c
o
l
a
s
```

## 1.12 Modules

<h3>ğŸ”¸ main.py</h3>

```py
# í•­ìƒ ì‚¬ìš©í•  ê²ƒë§Œ ê°€ì ¸ì˜¤ë„ë¡ !
from math import ceil, fsum as sexy_sum
from calculator import plus 

print(ceil(1.2))
print(sexy_sum([1, 2, 3, 4, 5, 6, 7]))
print(plus(2, 3))
```

<h3>ğŸ”¸ calcuator.py</h3>

```py
def plus(a, b):
  return a + b
```

<h3>ğŸ”¹ console</h3>

```md
2
28.0
5
```
# âš¡ 2. BUILDING A JOB SCRAPPER

## 2.0~1 What is Web Scrapping~What are We Building

íŒŒì´ì¬ìœ¼ë¡œ ì‚¬ì´íŠ¸ ìŠ¤í¬ë©í•‘í•˜ëŠ” ê¸°ëŠ¥ì„ ë§Œë“¤ ì˜ˆì • -

indeed í•œêµ­ ë²„ì „ì´ ìƒê²¨ì„œ ì¢€ í—·ê°ˆë¦´ ìˆ˜ ìˆìœ¼ë‹ˆ `https://www.indeed.com/jobs?q=python&limit=50` ë°”ë¡œ ì´ urlë¡œ ìŠ¤í¬ë©í•‘ í•˜ë„ë¡ í•  ê²ƒ !

stackOverflow jobì€ ì‚¬ë¼ì§„ ê±° ê°™ë‹¤,, ë‹¤ë¥¸ ì‚¬ì´íŠ¸ë¡œ ëŒ€ì²´í•˜ë˜ì§€ í•´ì„œ í…ŒìŠ¤íŠ¸ í•´ë³´ì.

## 2.2 Navigating with Python

<h3> ğŸ“Œ ìš°ì„  HTML ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì.</h3>

:::tip python requests
`https://docs.python-requests.org/en/latest/` í™œìš©í•˜ì—¬ Http Requests ì°Œë¥´ê¸°

`repl.it`ì—ì„œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ í•´ì£¼ì. requestsë¥¼ ê²€ìƒ‰í•˜ì—¬ `Python HTTP for Humans` ì„¤ì¹˜

```py
r = requests.get('https://api.github.com/user', auth=('user', 'pass'))
r.status_code
200
r.headers['content-type']
'application/json; charset=utf8'
r.encoding
'utf-8'
r.text
'{"type":"User"...'
r.json()
{'private_gists': 419, 'total_private_repos': 77, ...}
```

:::

<h3>ğŸ”¸ py</h3>

```py 
import requests

indeed_result = requests.get("https://www.indeed.com/jobs?q=python&limit=50")

print(indeed_result.text)
```

<h3>ğŸ”¹ console</h3>

html í…ìŠ¤íŠ¸ê°€ ì¶œë ¥ëœë‹¤.

```md
.
.
.
k\u0004My new jobs":[null,""],"job feed link\u0004There are new jobs":[null,""],"jobresults_tip_l_empty_variation_1\u0004Tip: Enter your city or zip code in the \"where\" box to show results in your area.":[null,"Tip: Enter your city or zip code in the \"where\" box to show results in your area."],"mobile_home_query_caption\u0004Job title, keywords, or company":[null,""],"near {0}":[null,""],"new count\u0004{0} new":[null,""],"new count / location separator\u0004in {0}":[null,""],"notice_message_for_empty_q_and_l\u0004Enter a job title or location to start a search":[null,""],"pill_filters\u0004All jobs":[null,""],"pill_filters\u0004Date Posted":[null,""],"pill_filters\u0004Last 14 days":[null,""],"pill_filters\u0004Last 24 hours":[null,""],"pill_filters\u0004Last 3 days":[null,""],"pill_filters\u0004Last 7 days":[null,""],"radius-slider-title\u0004Distance":[null,""],"recent search\u0004There is no recent search":[null,""],"recent search\u0004There is no recent search history.":[null,""],"recent search item\u0004go":[null,""],"recent search item\u0004{0} - {1}":[null,""],"recent_search_aria_label\u0004hide":[null,""],"recent_search_aria_label\u0004please tap the bottom of this page for back to search result.":[null,""],"recent_search_aria_label\u0004show":[null,""],"recent_search_ssr_label\u0004edit searches":[null,""],"recent_search_ssr_label\u0004finish":[null,""],"recent_searches_heading\u0004Search history / Saved Searches":[null,""],"rich search\u0004add filters":[null,""],"rich search\u0004dismiss":[null,""],"search":[null,""],"single search\u0004change query":[null,""],"{0} miles":[null,""],"{0} search suggestion":["{0} search suggestions","",""]};}).bind(this.mosaic.i18nOverrides)();
</script>
<script>window['sendPageLoadEndPing'] = function(pageId, tk, st) {var validPageIds = ['viewjob', 'serp']; if (!!Image && validPageIds.indexOf(pageId) > -1 && !!tk && !!st) {var href = '/rpc/pageLoadEnd?pageId=' + pageId + '&tk=' + tk + '&st=' + st + '&__=' + Math.random(); var img = new Image(); img.src = href;}}; window['sendPageLoadEndPing']("serp", "1g17eob8vghqc800", "1650591542559");</script><div class="mosaic-zone" id="mosaic-zone-serpBottomBody"><div id="mosaic-provider-signinprompt" class="mosaic mosaic-provider-signinprompt mosaic-rst"></div><div id="mosaic-provider-dislike-feedback" class="mosaic mosaic-provider-dislike-feedback"><div class="animatedToast i-unmask"><div class=""></div></div></div></div><script type="text/javascript">
                try {
                    window.mosaic.onMosaicApiReady(function() {
                        var zoneId = 'serpBottomBody';
                        var providers = window.mosaic.zonedProviders[zoneId];

                        if (providers) {
                            providers.filter(function(p) { return window.mosaic.lazyFns[p]; }).forEach(function(p) {
                                return window.mosaic.api.loadProvider(p);
                            });
                        }
                    });
                 } catch (e) {};
                </script></body>
</html>
```
<h3> ğŸ“Œ <u>beautiful soup</u> ì„ í™œìš©í•˜ì—¬ í•„ìš”í•œ ì •ë³´ë§Œ ê°€ì ¸ì˜¤ì</h3>

:::tip BeautifulSoup
`https://www.crummy.com/software/BeautifulSoup/bs4/doc/`

`repl.it`ì—ì„œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ í•´ì£¼ì. `beautifulsoup4` ê²€ìƒ‰í•˜ì—¬ ì„¤ì¹˜

```py
from bs4 import BeautifulSoup
soup = BeautifulSoup(html_doc, 'html.parser')

print(soup.prettify())
```

```py
soup.title
# <title>The Dormouse's story</title>

soup.title.name
# u'title'

soup.title.string
# u'The Dormouse's story'

soup.title.parent.name
# u'head'

soup.p
# <p class="title"><b>The Dormouse's story</b></p>

soup.p['class']
# u'title'

soup.a
# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>

soup.find_all('a')
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

soup.find(id="link3")
# <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>
```
:::

## 2.3 Extracting Indeed Pages

í˜ì´ì§• ë²ˆí˜¸ê°€ `<div class="pagination">...`ë¡œ ì´ë£¨ì–´ì ¸ìˆë‹¤. í•´ë‹¹ ë‚´ìš© íŒŒì‹±í•´ë³´ì.

<h3>ğŸ”¸ py</h3>

```py
import requests
from bs4 import BeautifulSoup

indeed_result = requests.get("https://www.indeed.com/jobs?q=python&limit=50")

indeed_soup = BeautifulSoup(indeed_result.text, 'html.parser')

# ì „ì²´ ì¶œë ¥
# print(indeed_soup)

# <title>
# print(indeed_soup.title)

# í˜ì´ì§• div ì°¾ê¸°
pagination = indeed_soup.find("div", {"class": "pagination"})

# a link ì°¾ê¸°
pages = pagination.find_all('a')

# <span class="pn">ë²ˆí˜¸</span> ì°¾ê¸°

spans = []

for page in pages:
  spans.append(page.find("span"))

print("---------span/class:pn---------")
print(spans)
print("---------Listì—ì„œ ê°€ì¥ ë§ˆì§€ë§‰ item---------")
 # -1: ë§ˆì§€ë§‰ì—ì„œë¶€í„° ì‹œì‘í•´ì„œ ì²« item
print(spans[-1])
print("---------Listì—ì„œ ê°€ì¥ ë§ˆì§€ë§‰ item ë¹¼ê³  ì¡°íšŒ---------")
# ë§ˆì§€ë§‰ ì•„ì´í…œ ë¹¼ê³  ì¡°íšŒ
# spans[0:5] 0ë¶€í„° 5ê°œ ì¡°íšŒ
print(spans[:-1])

```

<h3>ğŸ”¹ console</h3>

```md
---------span/class:pn---------
[<span class="pn">2</span>, <span class="pn">3</span>, <span class="pn">4</span>, <span class="pn">5</span>, <span class="pn"><span class="np"><svg fill="none" height="24" width="24"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6-6-6z" fill="#2D2D2D"></path></svg></span></span>]
---------Listì—ì„œ ê°€ì¥ ë§ˆì§€ë§‰ item---------
<span class="pn"><span class="np"><svg fill="none" height="24" width="24"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6-6-6z" fill="#2D2D2D"></path></svg></span></span>
---------Listì—ì„œ ê°€ì¥ ë§ˆì§€ë§‰ item ë¹¼ê³  ì¡°íšŒ---------
[<span class="pn">2</span>, <span class="pn">3</span>, <span class="pn">4</span>, <span class="pn">5</span>]
```

## 2.4 Extracting Indeed Pages part Two

`pages.append(link.("span").string)` ëŠ” `pages.append(link.string)` ì™€ ê°™ë‹¤.
**beautiful soup** ì—ì„œ link > span ì•ˆì— stringì„ ì½ì–´ì¤€ë‹¤.

<h3>ğŸ”¸ py</h3>

```py
import requests
from bs4 import BeautifulSoup

indeed_result = requests.get("https://www.indeed.com/jobs?q=python&limit=50")

indeed_soup = BeautifulSoup(indeed_result.text, 'html.parser')

# í˜ì´ì§• div ì°¾ê¸°
pagination = indeed_soup.find("div", {"class": "pagination"})

# a link ì°¾ê¸°
links = pagination.find_all('a')

# <span class="pn">ë²ˆí˜¸</span> ì°¾ê¸°
pages = []
for link in links[:-1]:
  #pages.append(link.("span").string) ì™€ ê°™ìŒ.
  # intë¡œ cast
  pages.append(int(link.string))

# htmlë‚´ ë§ˆì§€ë§‰ í˜ì´ì§€
max_page = pages[-1]
print(max_page)
```

<h3>ğŸ”¹ console</h3>

```md
5
```

## 2.5 Requesting Each Page

<h3>ğŸ“Œ ëª¨ë“  í˜ì´ì§€ë¥¼ requestí•´ë³´ì.</h3>

íŒŒì¼ì„ ë”°ë¡œ ë‘ì–´ functionì„ ì •ë¦¬í•´ì¤¬ë‹¤.

<h3>ğŸ”¸ main.py</h3>

```py
from indeed import extract_indeed_pages, extract_indeed_jobs

# page ë²ˆí˜¸ ì „ë¶€ ì¡°íšŒ í›„,
last_indeed_page = extract_indeed_pages()

# request ë‚ ë ¤ë³´ê¸° status 200 ì„±ê³µ ì¶œë ¥
extract_indeed_jobs(last_indeed_page)
```

<h3>ğŸ”¸ indeed.py</h3>

```py
import requests
from bs4 import BeautifulSoup

LIMIT = 50
URL = f"https://www.indeed.com/jobs?q=python&limit={LIMIT}"

# pagination ì¤‘ ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸
def extract_indeed_pages():
  result = requests.get(URL)
  
  soup = BeautifulSoup(result.text, 'html.parser')
  
  # htmlë‚´ ë§ˆì§€ë§‰ í˜ì´ì§€ ì°¾ê¸°
  pagination = soup.find("div", {"class": "pagination"})
  
  links = pagination.find_all('a')
  
  pages = []
  for link in links[:-1]:
    pages.append(int(link.string))
  
  max_page = pages[-1]
  return max_page

# ê° pageì˜ start index êµ¬í•˜ì—¬ request ë‚ ë ¤ë³´ê¸°
#  range(N): Nê°œì˜ ë°°ì—´ì„ ìƒì„±í•´ì¤Œ.
def extract_indeed_jobs(last_page):
  for page in range(last_page):
    result = requests.get(f"{URL}&start={page*LIMIT}")
    print(result.status_code)
```

<h3>ğŸ”¹ console</h3>

```md
200
200
200
200
200
```

## 2.6 Extracting Titles

ì‚¬ì´íŠ¸ ë§ˆí¬ì—…ì´ ì¢€ ë‹¬ë¼ì ¸ì„œ ê°•ì˜ë¥¼ ë“£ê³ , ë‚´ ë°©ì‹ëŒ€ë¡œ ìˆ˜ì •í•˜ì—¬ titleì„ ê°€ì ¸ì™”ë‹¤.

ì—¬ê¸°ì„œë¶€í„° ê°•ì˜ì™€ ì½”ë“œê°€ ì¢€ ë‹¤ë¥¼ ì˜ˆì •,,

<h3>ğŸ”¸ py</h3>

```py
import requests
from bs4 import BeautifulSoup

LIMIT = 50
URL = f"https://www.indeed.com/jobs?q=python&limit={LIMIT}"

# pagination ì¤‘ ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸
def extract_indeed_pages():
  result = requests.get(URL)
  
  soup = BeautifulSoup(result.text, 'html.parser')
  
  # htmlë‚´ ë§ˆì§€ë§‰ í˜ì´ì§€ ì°¾ê¸°
  pagination = soup.find("div", {"class": "pagination"})
  
  links = pagination.find_all('a')
  
  pages = []
  for link in links[:-1]:
    pages.append(int(link.string))
  
  max_page = pages[-1]
  return max_page

# ê° pageì˜ start index êµ¬í•˜ì—¬ request ë‚ ë ¤ë³´ê¸°
def extract_indeed_jobs(last_page):
  jobs = []
  # 1í˜ì´ì§€ë¡œ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ forë¬¸ ì£¼ì„ ì²˜ë¦¬
  #for page in range(last_page):
  result = requests.get(f"{URL}&start={0*LIMIT}")
  soup = BeautifulSoup(result.text, 'html.parser')
  results = soup.find_all("div", {"class": "job_seen_beacon"})
  for result in results:
    title = result.find("td", {"class": "resultContent"}).find("h2", {"class": "jobTitle"}).find("span", {"class": None})["title"]
    print(title) # title
  return jobs
```

<h3>ğŸ”¹ console</h3>

```md
Python/Django Developer
Software Development (All Levels)
Python - Machine Learning SME
Coding teacher for teaching Scratch & Python
Python Developer
Python Developer
Fraud Modeler - Credit Cards / Banking
Logistics Analyst
Online Python Teacher
Python Engineer
Python developer
Python Developer
Analytic Methodologist
Data Scientist with Python
Remote Python Developer
Remote Python Developer
Python Developer Ex Google
Python Developer
3D Solutions Analyst (REMOTE)
Entry Level Software Engineer
Backend Engineer (Python)
Entry Level Python Developer
Data Analyst
Lead Python Developer
Python Developer
Python Developer
Python developer
Data Scientist
AWS Python Developer
Data Analyst: Technical Business Intelligence
USSTRATCOM - Analytic Methodologist
Informatica for Google BigQuery
MACHINE LEARNING DATA SCIENTIST - PYTHON AND R
Python Developer
Database Developer
Basketball Data Scientist (remote opportunity)
Python Developer
Python Developer with AWs
Python Developer
Junior Trader (Remote)
Python Developer
Jr. Software Engineer
Python Developer
Backend software engineer (python)
Python Developer
Software Developer â€“ Entry Level
Python Engineer
Data Scientist
Python Developer
Python Developer
```

## 2.7 Extracting Companies

<h3>ğŸ”¸ indeed.py</h3>

```py
import requests
from bs4 import BeautifulSoup

LIMIT = 50
URL = f"https://www.indeed.com/jobs?q=python&limit={LIMIT}"

# pagination ì¤‘ ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸
def extract_indeed_pages():
  result = requests.get(URL)
  
  soup = BeautifulSoup(result.text, 'html.parser')
  
  # htmlë‚´ ë§ˆì§€ë§‰ í˜ì´ì§€ ì°¾ê¸°
  pagination = soup.find("div", {"class": "pagination"})
  
  links = pagination.find_all('a')
  
  pages = []
  for link in links[:-1]:
    pages.append(int(link.string))
  
  max_page = pages[-1]
  return max_page

# ê° pageì˜ start index êµ¬í•˜ì—¬ request ë‚ ë ¤ë³´ê¸°
def extract_indeed_jobs(last_page):
  jobs = []
  # 1í˜ì´ì§€ë¡œ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ forë¬¸ ì£¼ì„ ì²˜ë¦¬
  #for page in range(last_page):
  result = requests.get(f"{URL}&start={0*LIMIT}")
  soup = BeautifulSoup(result.text, 'html.parser')
  results = soup.find_all("div", {"class": "job_seen_beacon"})
  for result in results:
    resultContent = result.find("td", {"class": "resultContent"})
    # title
    title = resultContent.find("h2", {"class": "jobTitle"}).find("span", {"class": None})["title"]
    # company
    company = resultContent.find("div", {"class":"company_location"}).find("span", {"class": "companyName"}).string
    print(f"{title} >>> {company}")
  return jobs
```

<h3>ğŸ”¹ console</h3>

```md
Software Development (All Levels) >>> Insurity
Entry Level Software Engineer >>> Avant
Python/Django Developer >>> Delta
Python - Machine Learning SME >>> Envision
Coding teacher for teaching Scratch & Python >>> YoumeCan Education Center
Python Developer >>> Mechlance INC
Python Developer >>> Mobile Mechanic
Fraud Modeler - Credit Cards / Banking >>> Acunor
Logistics Analyst >>> Lululemon
Software Engineer (Early Career) >>> Apple
Python Engineer >>> Highbrow-Tech
Online Python Teacher >>> YC Solutions Pvt. Ltd.
Python Developer >>> Integration Developer Network LLC
Python/Odoo ERP Developer >>> Novobi, LLC
Python developer >>> Vyze, Inc.
Remote Python Developer >>> Piper Companies
Software Engineer I ( 100% Remote) >>> Windstream Communications
Data Scientist with Python >>> Techladder
Analytic Methodologist >>> Constellation West
Remote Python Developer >>> CTI Consulting
Python Developer Ex Google >>> Laiba Technologies
3D Solutions Analyst (REMOTE) >>> Under Armour
Entry Level Python Developer >>> Marlabs
Backend Engineer (Python) >>> Metaverse HQ
Python Developer >>> WorkCog inc
Data Analyst >>> Young Life
MACHINE LEARNING DATA SCIENTIST - PYTHON AND R >>> InspiHER Tech
Lead Python Developer >>> Interaslabs.llc
Python Developer >>> Yaddala Consulting
Data Analyst: Technical Business Intelligence >>> Barstool Sports
USSTRATCOM - Analytic Methodologist >>> Apogee Engineering, LLC
AWS Python Developer >>> Inscope Global Solutions
Data Scientist >>> FIIDUS
Informatica for Google BigQuery >>> Kaygen
Python Developer >>> Business Intelli Solutions
Python Developer >>> AGM Tech Solutions, INC.
Database Developer >>> Integration Developer Network LLC
Python developer >>> Stefanini Group
Python Developer >>> Aquatic Capital Management
Python Developer >>> Santex Group
Python Developer with AWs >>> Innovative BI Solutions Inc
Basketball Data Scientist (remote opportunity) >>> Madison Square Garden Entertainment
Jr. Software Engineer >>> NBCUniversal
Backend software engineer (python) >>> Benchmark IT Solutions
Python Developer >>> Swan Software Solutions
Python Developer >>> Benedsoft
Software Developer â€“ Entry Level >>> Grant Street Group
Python Developer >>> Infinizi IT Solutions Pvt. Ltd.
Python Engineer >>> Techno corporation inc
Python Developer >>> Morgan Stanley
```

## 2.8 Extracting Locations and Finishing up

`id`ê¹Œì§€ ê°€ì ¸ì˜¤ë„ë¡ íŒŒì‹±í•˜ê¸°

`https://www.indeed.com/viewjob?jk={id}` ì™€ ê°™ì´ ë§í¬ ìƒì„± ê°€ëŠ¥!

<h3>ğŸ”¸ main.py</h3>

```py
from indeed import extract_indeed_pages, extract_indeed_jobs

last_indeed_page = extract_indeed_pages()

indeed_jobs = extract_indeed_jobs(last_indeed_page)

print(indeed_jobs)
```

<h3>ğŸ”¸ indeed.py</h3>

```py
import requests
from bs4 import BeautifulSoup

LIMIT = 50
URL = f"https://www.indeed.com/jobs?q=python&limit={LIMIT}"

# pagination ì¤‘ ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸
def extract_indeed_pages():
  result = requests.get(URL)
  
  soup = BeautifulSoup(result.text, 'html.parser')
  
  # htmlë‚´ ë§ˆì§€ë§‰ í˜ì´ì§€ ì°¾ê¸°
  pagination = soup.find("div", {"class": "pagination"})
  
  links = pagination.find_all('a')
  
  pages = []
  for link in links[:-1]:
    pages.append(int(link.string))
  
  max_page = pages[-1]
  return max_page

# íšŒì‚¬ ì •ë³´ íŒŒì‹±
def extract_job(html):
  resultContent = html.find("div", {"class": "job_seen_beacon"}).find("td", {"class": "resultContent"})
  # id
  id = html["data-jk"]
  # title
  title = resultContent.find("h2", {"class": "jobTitle"}).find("span", {"class": None})["title"]
  # company
  company = resultContent.find("div", {"class": "company_location"}).find("span", {"class": "companyName"}).string
  # location
  location = resultContent.find("div", {"class": "companyLocation"}).string
  
  return {'id': id, 'title': title, 'company': company, 'location': location, 'link': f"https://www.indeed.com/viewjob?jk={id}"}

# ê° pageì˜ start index êµ¬í•˜ì—¬ request ë‚ ë ¤ë³´ê¸°
def extract_indeed_jobs(last_page):
  jobs = []
  # ëª¨ë“  í˜ì´ì§€ ì§ì—… ì¡°íšŒ
  for page in range(last_page):
    print(f"Scrapping page {page}")
    result = requests.get(f"{URL}&start={page*LIMIT}")
    soup = BeautifulSoup(result.text, 'html.parser')
    results = soup.find_all("a", {"class": "tapItem"})
    for result in results:
      job = extract_job(result)
      jobs.append(job)
  return jobs
```

<h3>ğŸ”¹ console</h3>

```md
Scrapping page 0
Scrapping page 1
Scrapping page 2
Scrapping page 3
Scrapping page 4
[{'id': 'b6d26975703d41c2', 'title': 'Python - Machine Learning SME', 'company': 'Envision', 'location': 'Remote', 'link': 'https://www.indeed.com/viewjob?jk=b6d26975703d41c2'}, {'id': '5a91a49780ab17df', 'title': 'Sr Data Scientist', 'company': 'Zillow', 'location': 'Remote', 'link': 'https://www.indeed.com/viewjob?jk=5a91a49780ab17df'}, {'id': '2bcd843c58159429', 'title': 'Software Engineer (Early Career)', 'company': 'Apple', 'location': None, 'link': 'https://www.indeed.com/viewjob?jk=2bcd843c58159429'}, {'id': '6d0ab231885eac14', 'title': 'GIS Analyst', 'company': 'Bruce Harris & Associates, Inc', 'location': 'Remote', 'link': 'https://www.indeed.com/viewjob?jk=6d0ab231885eac14'}, {'id': '788dc9dd8ade27a6', 'title': 'Python/Django Developer', 'company': 'Delta', 'location': None, 'link': 'https://www.indeed.com/viewjob?jk=788dc9dd8ade27a6'}, {'id': 'ebcc2ad72eda66fb', 'title': 'QT Software Engineer (Python and C++)', 'company': 'TriSearch', 'location': 'Remote', 'link': 'https://www.indeed.com/viewjob?jk=ebcc2ad72eda66fb'}, {'id': '57654f0e7ccfc3b7', 'title': ' ... ìƒëµ
```

## .. ğŸ¤ progress

## 2.9 StackOverflow Pages

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 2.10 StackOverflow extract jobs

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 2.11 StackOverflow extract job

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 2.12 StackOverflow extract job part Two

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 2.13 StackOverflow Finish

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 2.14 What is CSV

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 2.15 Saving to CSV

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 2.16 OMG THIS IS AWESOME

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

# âš¡ 3. GET READY FOR DJANGO

## 3.0 Django is AWESOME

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 3.1 *args **kwargs

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 3.2 Intro to Object Oriented Programming

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 3.3 Methods part One

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 3.4 Methods part Two

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 3.5 Extending Classes

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 3.6 Whats Next

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

# âš¡ 4. 2020 BONUS CLASS

## 4.0 Welcome to 2020 Update

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 4.1 Introduction to Flask

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 4.2 Dynamic URLs and Templates

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 4.3 Forms and Query Arguments

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 4.4 Scrapper Integration

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 4.5 Faster Scrapper

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 4.6 Rendering Jobs!

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 4.7 Export Route

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 4.8 File Download

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 4.9 Recap

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>

## 4.10 Conclusions

<h3>ğŸ”¸ py</h3>

<h3>ğŸ”¹ console</h3>


## Reference


[Pythoneìœ¼ë¡œ ì›¹ ìŠ¤í¬ë˜í¼ ë§Œë“¤ê¸°](https://nomadcoders.co/python-for-beginners/lobby)
[replit](https://replit.com/)
[Python library](https://docs.python.org/3/library/index.html)